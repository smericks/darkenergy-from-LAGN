{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import jax_cosmo\n",
    "import tdc_sampler\n",
    "from scipy.stats import norm\n",
    "from lenstronomy.Analysis.kinematics_api import KinematicsAPI\n",
    "from tdc_utils import jax_kin_distance_ratio\n",
    "from matplotlib.lines import Line2D\n",
    "from Utils.inference_utils import median_sigma_from_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ede500",
   "metadata": {},
   "source": [
    "First, set up ground truth kinematics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be5aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_APERTURE = 0.725\n",
    "PSF_FWHM = 0.5\n",
    "\n",
    "kwargs_aperture = {\n",
    "    'aperture_type': 'shell', \n",
    "    'r_in': 0., \n",
    "    'r_out': R_APERTURE,\n",
    "    'center_ra': 0, 'center_dec': 0}\n",
    "\n",
    "kwargs_seeing = {'psf_type': 'GAUSSIAN', 'fwhm': PSF_FWHM}\n",
    "\n",
    "kwargs_numerics_galkin = { \n",
    "    'interpol_grid_num': 1000,  # numerical interpolation, should converge -> infinity\n",
    "    'log_integration': True,  # log or linear interpolation of surface brightness and mass models\n",
    "    'max_integrate': 100, 'min_integrate': 0.001}  # lower/upper bound of numerical integrals\n",
    "\n",
    "kwargs_model = {\n",
    "    'lens_model_list':['SPP'],\n",
    "    'lens_light_model_list':['SERSIC']\n",
    "}\n",
    "\n",
    "anisotropy_model = 'const'\n",
    "\n",
    "kinematicsAPI = KinematicsAPI(0.5, 2., kwargs_model, \n",
    "    kwargs_aperture, kwargs_seeing, anisotropy_model, \n",
    "    kwargs_numerics_galkin=kwargs_numerics_galkin, \n",
    "    lens_model_kinematics_bool=[True, False],\n",
    "    sampling_number=5000,MGE_light=True)\n",
    "\n",
    "gt_cosmo = jax_cosmo.Cosmology(h=jnp.float32(70./100),\n",
    "                        Omega_c=jnp.float32(0.3-0.05), # \"cold dark matter fraction\", OmegaM = 0.3\n",
    "                        Omega_b=jnp.float32(0.05), # \"baryonic fraction\"\n",
    "                        Omega_k=jnp.float32(0.),\n",
    "                        w0=jnp.float32(-1.),\n",
    "                        wa=jnp.float32(0.),\n",
    "                        sigma8 = jnp.float32(0.8), n_s=jnp.float32(0.96))\n",
    "\n",
    "\n",
    "def ground_truth_veldisp(theta_E,gamma_lens,R_sersic,n_sersic):\n",
    "\n",
    "    # TODO: I messed this up!! Should be sqrt() of this...\n",
    "    distance_scaling_factor = np.sqrt(\n",
    "            kinematicsAPI._kwargs_cosmo['d_s'] / kinematicsAPI._kwargs_cosmo['d_ds'])\n",
    "\n",
    "    kwargs_anisotropy = {'beta': 0.}\n",
    "\n",
    "    kwargs_lens = [{\n",
    "        'theta_E':theta_E, \n",
    "        'gamma':gamma_lens, \n",
    "        \"center_x\":0., \n",
    "        \"center_y\":0.\n",
    "    }]\n",
    "\n",
    "    kwargs_lens_light = [{\n",
    "        'amp': 10.,\n",
    "        'R_sersic': R_sersic,\n",
    "        'n_sersic': n_sersic,\n",
    "        'center_x': 0.,\n",
    "        'center_y': 0.,\n",
    "    }]\n",
    "\n",
    "    vel_disp_numerical = kinematicsAPI.velocity_dispersion(kwargs_lens, \n",
    "        kwargs_lens_light, kwargs_anisotropy, r_eff=R_sersic, theta_E=theta_E)\n",
    "\n",
    "    return vel_disp_numerical, distance_scaling_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b9ec0",
   "metadata": {},
   "source": [
    "Now, load in all of the pre-computed data products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc1dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data vector\n",
    "data_vectors_folder = ('/Users/smericks/Desktop/StrongLensing/darkenergy-from-LAGN/'+\n",
    "    'DataVectors/src_mag_cut_silver_debiased/gold_quads/')\n",
    "\n",
    "inputs_dict = {}\n",
    "input_keys = ['lens_param_samps','z_lens_truth','z_src_truth',\n",
    "              'theta_E_truth','gamma_truth','fpd_samps',\n",
    "            'lens_light_parameters_R_sersic_truth',\n",
    "            'lens_light_parameters_n_sersic_truth',\n",
    "            'fpd01_truth','fpd02_truth','fpd03_truth',\n",
    "            'td01_truth','td02_truth','td03_truth',\n",
    "            'measured_td','measured_prec']\n",
    "\n",
    "h5f = h5py.File((data_vectors_folder+'gold_quads.h5'), 'r')\n",
    "for key in input_keys:\n",
    "    inputs_dict[key] = h5f.get(key)[:]\n",
    "h5f.close()\n",
    "\n",
    "cJ_samples = np.empty((10,5000,1))\n",
    "sigma_v_truth_list = np.empty(10)\n",
    "c_sqrtJ_truth_list = np.empty(10)\n",
    "sigma_v_measured = np.empty((10,1))\n",
    "sigma_v_likelihood_prec = np.empty((10,1,1))\n",
    "sigma_v_measurement_error = 5. # NOTE: assuming 5 km/s measurement error on kinematics...\n",
    "\n",
    "# fill in c*sqrt(J) samples\n",
    "for i in range(0,10):\n",
    "\n",
    "    # compute ground truth kinematics\n",
    "    vdisp_truth, vdisp_dist_scaling = ground_truth_veldisp(inputs_dict['theta_E_truth'][i],\n",
    "        inputs_dict['gamma_truth'][i],\n",
    "        inputs_dict['lens_light_parameters_R_sersic_truth'][i],\n",
    "        inputs_dict['lens_light_parameters_n_sersic_truth'][i])\n",
    "    # re-scale based on redshift & ground truth cosmology\n",
    "    cJ_truth = vdisp_truth/vdisp_dist_scaling\n",
    "    c_sqrtJ_truth_list[i] = cJ_truth\n",
    "    z_l = inputs_dict['z_lens_truth'][i]\n",
    "    z_s = inputs_dict['z_src_truth'][i]\n",
    "    ds_div_dds = jax_kin_distance_ratio(gt_cosmo,z_l,z_s)\n",
    "    sigma_v_truth = np.sqrt(ds_div_dds)*cJ_truth\n",
    "    sigma_v_truth_list[i] = sigma_v_truth.item()\n",
    "    # emulate the measurement from ground truth\n",
    "    sigma_v_measured[i,0] = norm.rvs(loc=sigma_v_truth,scale=sigma_v_measurement_error)    \n",
    "    sigma_v_likelihood_prec[i,0,0] = 1/(sigma_v_measurement_error**2)\n",
    "\n",
    "    # now, track the c*sqrt(J) samples from the mass model\n",
    "    vdisp_samps_lens = np.load(data_vectors_folder+'lens00'+str(i)+'_vdisp.npy')\n",
    "    cJ_samples[i,:,0] = vdisp_samps_lens*vdisp_dist_scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15566846",
   "metadata": {},
   "source": [
    "Now let's investigate the joint mass model posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b6801",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_idx = 0\n",
    "\n",
    "posterior_samps = np.stack((\n",
    "    inputs_dict['lens_param_samps'][lens_idx,:,3], # gamma_lens\n",
    "    inputs_dict['fpd_samps'][lens_idx,:,0], # fpd01\n",
    "    inputs_dict['fpd_samps'][lens_idx,:,1], # fpd02\n",
    "    inputs_dict['fpd_samps'][lens_idx,:,2], # fpd03\n",
    "    cJ_samples[lens_idx,:,0]\n",
    ")).T\n",
    "\n",
    "truth_params = [\n",
    "    inputs_dict['gamma_truth'][lens_idx],\n",
    "    inputs_dict['fpd01_truth'][lens_idx],\n",
    "    inputs_dict['fpd02_truth'][lens_idx],\n",
    "    inputs_dict['fpd03_truth'][lens_idx],\n",
    "    c_sqrtJ_truth_list[lens_idx]\n",
    "]\n",
    "\n",
    "\n",
    "import corner\n",
    "figure = corner.corner(posterior_samps,plot_datapoints=False,\n",
    "            color='goldenrod',levels=[0.68,0.95],fill_contours=True,\n",
    "            labels=['$\\gamma_{lens}$','$\\Delta \\phi_{01}$','$\\Delta \\phi_{02}$','$\\Delta \\phi_{03}$','$c\\sqrt{\\mathcal{J}}$ (km/s)'],\n",
    "            dpi=200,truths=truth_params,truth_color='black',\n",
    "            fig=None,label_kwargs={'fontsize':20},smooth=0.7,hist_kwargs={'density':True})\n",
    "\n",
    "# TODO: what happens if we Gaussianize?\n",
    "\n",
    "print('posterior samps shape: ', posterior_samps.shape)\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "def gaussianized_samples(posterior_samps):\n",
    "\n",
    "    Mu = np.mean(posterior_samps,axis=0)\n",
    "    Cov = np.cov(posterior_samps,rowvar=False)\n",
    "\n",
    "    gaussianized_samps = multivariate_normal.rvs(mean=Mu,cov=Cov,size=5000)\n",
    "\n",
    "    return gaussianized_samps\n",
    "\n",
    "gaussian_posterior_samps = gaussianized_samples(posterior_samps)\n",
    "gaussian_posterior_samps500 = gaussianized_samples(posterior_samps[:500])\n",
    "\n",
    "corner.corner(gaussian_posterior_samps,plot_datapoints=False,\n",
    "            color='maroon',levels=[0.68,0.95],fill_contours=True,\n",
    "            labels=['$\\gamma_{lens}$','$\\Delta \\phi_{01}$','$\\Delta \\phi_{02}$','$\\Delta \\phi_{03}$','$c\\sqrt{\\mathcal{J}}$ (km/s)'],\n",
    "            dpi=200,truths=truth_params,truth_color='black',\n",
    "            fig=figure,label_kwargs={'fontsize':20},smooth=0.7,hist_kwargs={'density':True})\n",
    "corner.corner(gaussian_posterior_samps500,plot_datapoints=False,\n",
    "            color='turquoise',levels=[0.68,0.95],fill_contours=True,\n",
    "            labels=['$\\gamma_{lens}$','$\\Delta \\phi_{01}$','$\\Delta \\phi_{02}$','$\\Delta \\phi_{03}$','$c\\sqrt{\\mathcal{J}}$ (km/s)'],\n",
    "            dpi=200,truths=truth_params,truth_color='black',\n",
    "            fig=figure,label_kwargs={'fontsize':20},smooth=0.7,hist_kwargs={'density':True})\n",
    "\n",
    "custom_lines = [\n",
    "    Line2D([0], [0], color='goldenrod', lw=4),\n",
    "    Line2D([0], [0], color='maroon', lw=4),\n",
    "    Line2D([0], [0], color='turquoise', lw=4)\n",
    "]\n",
    "\n",
    "custom_labels = [\n",
    "    'Original Samples','Gaussianized Samples','Gaussianized from 500'\n",
    "]\n",
    "\n",
    "axes = np.array(figure.axes).reshape((5,5))\n",
    "axes[0,4].legend(custom_lines,custom_labels,frameon=False,fontsize=16)\n",
    "plt.suptitle('Lens %d'%(lens_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503bb585",
   "metadata": {},
   "source": [
    "Now, let's run the inference!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be843e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that inclusion of lambda_int works\n",
    "quad_kin_lklhd = tdc_sampler.TDCKinLikelihood(\n",
    "    td_measured=inputs_dict['measured_td'][:10],\n",
    "    td_likelihood_prec=inputs_dict['measured_prec'][:10],\n",
    "    sigma_v_measured=sigma_v_measured,\n",
    "    sigma_v_likelihood_prec=sigma_v_likelihood_prec,\n",
    "    fpd_samples=inputs_dict['fpd_samps'][:10],\n",
    "    gamma_pred_samples=inputs_dict['lens_param_samps'][:10,:,3],\n",
    "    kin_pred_samples=cJ_samples,\n",
    "    z_lens=inputs_dict['z_lens_truth'][:10],\n",
    "    z_src=inputs_dict['z_src_truth'][:10],\n",
    "    cosmo_model='LCDM_lambda_int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e4c1f",
   "metadata": {},
   "source": [
    "Repeat the inference with Gaussianized chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c82af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "def gaussianized_samples(posterior_samps):\n",
    "\n",
    "    Mu = np.mean(posterior_samps,axis=0)\n",
    "    Cov = np.cov(posterior_samps,rowvar=False)\n",
    "\n",
    "    gaussianized_samps = multivariate_normal.rvs(mean=Mu,cov=Cov,size=5000)\n",
    "\n",
    "    return gaussianized_samps\n",
    "\n",
    "fpd_samples_gaussianized = np.empty((10,5000,3))\n",
    "gamma_pred_samples_gaussianized = np.empty((10,5000))\n",
    "cJ_samples_gaussianized = np.empty((10,5000,1))\n",
    "\n",
    "for lens_idx in range(0,10):\n",
    "    posterior_samps = np.stack((\n",
    "        inputs_dict['lens_param_samps'][lens_idx,:,3], # gamma_lens\n",
    "        inputs_dict['fpd_samps'][lens_idx,:,0], # fpd01\n",
    "        inputs_dict['fpd_samps'][lens_idx,:,1], # fpd02\n",
    "        inputs_dict['fpd_samps'][lens_idx,:,2], # fpd03\n",
    "        cJ_samples[lens_idx,:,0]\n",
    "    )).T\n",
    "\n",
    "    gaussianized_samps = gaussianized_samples(posterior_samps)\n",
    "\n",
    "    # fill-in empty arrays\n",
    "    fpd_samples_gaussianized[lens_idx] = gaussianized_samps[:,1:4]\n",
    "    gamma_pred_samples_gaussianized[lens_idx] = gaussianized_samps[:,0]\n",
    "    cJ_samples_gaussianized[lens_idx,:,0] = gaussianized_samps[:,4]\n",
    "        \n",
    "\n",
    "quad_kin_lklhd_gaussianized_samps = tdc_sampler.TDCKinLikelihood(\n",
    "    td_measured=inputs_dict['measured_td'][:10],\n",
    "    td_likelihood_prec=inputs_dict['measured_prec'][:10],\n",
    "    sigma_v_measured=sigma_v_measured,\n",
    "    sigma_v_likelihood_prec=sigma_v_likelihood_prec,\n",
    "    fpd_samples=fpd_samples_gaussianized,\n",
    "    gamma_pred_samples=gamma_pred_samples_gaussianized,\n",
    "    kin_pred_samples=cJ_samples_gaussianized,\n",
    "    z_lens=inputs_dict['z_lens_truth'][:10],\n",
    "    z_src=inputs_dict['z_src_truth'][:10],\n",
    "    cosmo_model='LCDM_lambda_int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_sampling_chain = tdc_sampler.fast_TDC([quad_kin_lklhd],num_emcee_samps=5000,\n",
    "            n_walkers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianized_imp_sampling_chain = tdc_sampler.fast_TDC([quad_kin_lklhd_gaussianized_samps],num_emcee_samps=5000,\n",
    "            n_walkers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb4f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence_by_walker(samples_mcmc, param_mcmc, n_walkers, verbose = False):\n",
    "    n_params = samples_mcmc.shape[2]\n",
    "    n_step = int(samples_mcmc.shape[1])\n",
    "    chain = samples_mcmc\n",
    "    mean_pos = np.zeros((n_params, n_step))\n",
    "    median_pos = np.zeros((n_params, n_step))\n",
    "    std_pos = np.zeros((n_params, n_step))\n",
    "    q16_pos = np.zeros((n_params, n_step))\n",
    "    q84_pos = np.zeros((n_params, n_step))\n",
    "    # chain = np.empty((nwalker, nstep, ndim), dtype = np.double)\n",
    "    for i in np.arange(n_params):\n",
    "        for j in np.arange(n_step):\n",
    "            mean_pos[i][j] = np.mean(chain[:, j, i])\n",
    "            median_pos[i][j] = np.median(chain[:, j, i])\n",
    "            std_pos[i][j] = np.std(chain[:, j, i])\n",
    "            q16_pos[i][j] = np.percentile(chain[:, j, i], 16.)\n",
    "            q84_pos[i][j] = np.percentile(chain[:, j, i], 84.)\n",
    "    fig, ax = plt.subplots(n_params, sharex=True, figsize=(16, 2 * n_params))\n",
    "    if n_params == 1: ax = [ax]\n",
    "    last = n_step\n",
    "    burnin = int((9.*n_step) / 10.) #get the final value on the last 10% on the chain\n",
    "    for i in range(n_params):\n",
    "        if verbose :\n",
    "            print(param_mcmc[i], '{:.4f} +/- {:.4f}'.format(median_pos[i][last - 1], (q84_pos[i][last - 1] - q16_pos[i][last - 1]) / 2))\n",
    "        ax[i].plot(median_pos[i][:last], c='g')\n",
    "        ax[i].axhline(np.median(median_pos[i][burnin:last]), c='r', lw=1)\n",
    "        ax[i].fill_between(np.arange(last), q84_pos[i][:last], q16_pos[i][:last], alpha=0.4)\n",
    "        ax[i].set_ylabel(param_mcmc[i], fontsize=10)\n",
    "        ax[i].set_xlim(0, last)\n",
    "    return fig\n",
    "\n",
    "plot_convergence_by_walker(np.transpose(test_chain,axes=(1,0,2)),\n",
    "    ['$H_0$','$\\Omega_M$',\n",
    "     r'$\\mu(\\lambda_{int})$',r'$\\sigma(\\lambda_{int})$',\n",
    "     r'$\\mu(\\gamma_{lens})$',r'$\\sigma(\\gamma_{lens})$'],#'w$_0$','w$_a$'\n",
    "    20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_mean_gold = np.mean(inputs_dict['gamma_truth'])\n",
    "std_mean_gold = np.std(inputs_dict['gamma_truth'])\n",
    "\n",
    "\n",
    "exp_chains = [np.transpose(imp_sampling_chain,axes=(1,0,2)),\n",
    "              np.transpose(gaussianized_imp_sampling_chain,axes=(1,0,2))]\n",
    "exp_names = ['10 Gold with Kinematics',\n",
    "             'Gaussianized 10 Gold with Kinematics']\n",
    "burnin = [int(1000),int(1000)]\n",
    "colors = ['goldenrod', 'indianred']\n",
    "custom_labels = []\n",
    "\n",
    "custom_lines = []\n",
    "custom_labels = []\n",
    "for i,exp_chain in enumerate(exp_chains):\n",
    "\n",
    "\n",
    "    num_params = exp_chain.shape[2]\n",
    "     \n",
    "    if i ==0:\n",
    "\n",
    "        figure = corner.corner(exp_chain[:,burnin[i]:,:].reshape((-1,exp_chain.shape[2])),plot_datapoints=False,\n",
    "            color=colors[i],levels=[0.68,0.95],fill_contours=True,\n",
    "            labels= ['$H_0$','$\\Omega_M$',\n",
    "                r'$\\mu(\\lambda_{int})$',r'$\\sigma(\\lambda_{int})$',\n",
    "                r'$\\mu(\\gamma_{lens})$',r'$\\sigma(\\gamma_{lens})$'],\n",
    "            dpi=300,truths=[70.,0.3,1.,0.,mu_mean_gold,std_mean_gold],truth_color='black',\n",
    "            fig=None,label_kwargs={'fontsize':24},smooth=0.7)\n",
    "\n",
    "    else:\n",
    "\n",
    "        corner.corner(exp_chain[:,burnin[i]:,:].reshape((-1,exp_chain.shape[2])),plot_datapoints=False,\n",
    "            color=colors[i],levels=[0.68,0.95],fill_contours=True,\n",
    "            labels=['$H_0$','$\\Omega_M$',\n",
    "                r'$\\mu(\\lambda_{int})$',r'$\\sigma(\\lambda_{int})$',\n",
    "                r'$\\mu(\\gamma_{lens})$',r'$\\sigma(\\gamma_{lens})$'],\n",
    "            dpi=300,truths=[70.,0.3,1.,0.,mu_mean_gold,std_mean_gold],truth_color='black',\n",
    "            fig=figure,label_kwargs={'fontsize':24},smooth=0.7)\n",
    "        \n",
    "    custom_lines.append(Line2D([0], [0], color=colors[i], lw=4))\n",
    "\n",
    "    # calculate h0 constraint\n",
    "    h0, h0_sigma = median_sigma_from_samples(exp_chain[:,burnin[i]:,0].reshape((-1,1)),weights=None)\n",
    "    # construct label\n",
    "    custom_labels.append(exp_names[i]+':\\n $H_0$=%.2f$\\pm$%.2f'%(h0, h0_sigma))\n",
    "\n",
    "\"\"\"\n",
    "axes = np.array(figure.axes).reshape((3, 3))\n",
    "bounds = [[63,77],[1.91,2.095],[0.0,0.2]]\n",
    "for r in range(0,3):\n",
    "        for c in range(0,r+1):\n",
    "            if bounds is not None:\n",
    "                axes[r,c].set_xlim(bounds[c])\n",
    "                if r != c :\n",
    "                    axes[r,c].set_ylim(bounds[r])\n",
    "\n",
    "axes = np.array(figure.axes).reshape((3, 3))\n",
    "\"\"\"\n",
    "\n",
    "axes = np.array(figure.axes).reshape((num_params, num_params))\n",
    "axes[0,num_params-1].legend(custom_lines,custom_labels,frameon=False,fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350cb0d",
   "metadata": {},
   "source": [
    "Now, let's make the input for hierArc so we can compare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca90c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth Cosmology\n",
    "gt_cosmo = jax_cosmo.Cosmology(h=jnp.float32(70./100),\n",
    "                        Omega_c=jnp.float32(0.3-0.05), # \"cold dark matter fraction\", OmegaM = 0.3\n",
    "                        Omega_b=jnp.float32(0.05), # \"baryonic fraction\"\n",
    "                        Omega_k=jnp.float32(0.),\n",
    "                        w0=jnp.float32(-1.),\n",
    "                        wa=jnp.float32(0.),\n",
    "                        sigma8 = jnp.float32(0.8), n_s=jnp.float32(0.96))\n",
    "\n",
    "# Kinematic Settings\n",
    "R_APERTURE = 0.725\n",
    "PSF_FWHM = 0.5\n",
    "kwargs_aperture = {\n",
    "    'aperture_type': 'shell', \n",
    "    'r_in': 0., \n",
    "    'r_out': R_APERTURE,\n",
    "    'center_ra': 0, 'center_dec': 0}\n",
    "\n",
    "kwargs_seeing = {'psf_type': 'GAUSSIAN', 'fwhm': PSF_FWHM}\n",
    "\n",
    "kwargs_numerics_galkin = { \n",
    "    'interpol_grid_num': 1000,  # numerical interpolation, should converge -> infinity\n",
    "    'log_integration': True,  # log or linear interpolation of surface brightness and mass models\n",
    "    'max_integrate': 100, 'min_integrate': 0.001}  # lower/upper bound of numerical integrals\n",
    "\n",
    "kwargs_model = {\n",
    "    'lens_model_list':['SPP'],\n",
    "    'lens_light_model_list':['SERSIC']\n",
    "}\n",
    "\n",
    "anisotropy_model = 'const'\n",
    "beta_prior = norm(loc=0.,scale=0.1)\n",
    "\n",
    "# Dump relevant data vectors into a file\n",
    "mu_theta_E = np.mean(inputs_dict['lens_param_samps'][:10,:,0],axis=1)\n",
    "sigma_theta_E = np.std(inputs_dict['lens_param_samps'][:10,:,0],axis=1,ddof=1)\n",
    "mu_gamma = np.mean(inputs_dict['lens_param_samps'][:10,:,3],axis=1)\n",
    "sigma_gamma = np.std(inputs_dict['lens_param_samps'][:10,:,3],axis=1,ddof=1)\n",
    "R_sersic_truth = inputs_dict['lens_light_parameters_R_sersic_truth'][:10]\n",
    "n_sersic_truth = inputs_dict['lens_light_parameters_n_sersic_truth'][:10]\n",
    "sigma_v_measured\n",
    "sigma_v_likelihood_prec\n",
    "\n",
    "# Ddt has to be constructed with MCMC\n",
    "ddt_posterior_chains = []\n",
    "for ddt_l in range(0,10):\n",
    "    ddt_chain = tdc_sampler.TDCLikelihood.ddt_posterior_from_td_fpd(\n",
    "        inputs_dict['measured_td'][ddt_l],\n",
    "        inputs_dict['measured_prec'][ddt_l],\n",
    "        inputs_dict['fpd_samps'][ddt_l],\n",
    "        num_emcee_samps=10000\n",
    "    )\n",
    "    ddt_posterior_chains.append(ddt_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb0ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f7cc32",
   "metadata": {},
   "source": [
    "# Step 3: Build joint model posteriors #\n",
    "\n",
    "### p( gamma_lens, delta_phi, c $\\sqrt{J}$, b_ani | d_img, nu_int) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc126cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy.stats import truncnorm\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/smericks/Desktop/StrongLensing/darkenergy-from-LAGN/')\n",
    "import Utils.make_data_vectors as mdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50384c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the anistropy \"modeling prior\" here\n",
    "BETA_ANI_MU = 0.\n",
    "BETA_ANI_SIGMA = 0.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9425c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in NPE models\n",
    "\n",
    "npe_models = {\n",
    "    'gold':{},\n",
    "    'silver':{}\n",
    "}\n",
    "\n",
    "for quality in ['gold','silver']:\n",
    "    # load in NPE models\n",
    "    images_path = 'DataVectors/'+quality+'/image_models.h5'\n",
    "    h5 = h5py.File(images_path, 'r')\n",
    "    \n",
    "    npe_models[quality]['mu_npe'] = h5['mu_npe'][:]\n",
    "    npe_models[quality]['cov_npe'] = h5['cov_npe'][:]\n",
    "    h5.close()\n",
    "\n",
    "    # load in ground truth\n",
    "    df_path = 'DataVectors/'+quality+'/truth_metadata.csv'\n",
    "    truth_df = pd.read_csv(df_path)\n",
    "    npe_models[quality]['truth_df'] = truth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7654448",
   "metadata": {},
   "source": [
    "Compute fermat potential samples and write to .h5 files that store the lens model posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fermat potential + lens param samples\n",
    "#npe_models['gold']['quad_posteriors']['fpd_samps']\n",
    "#npe_models['gold']['quad_posteriors']['lens_param_samps']\n",
    "#npe_models['gold']['quad_posteriors']['beta_ani_samps']\n",
    "\n",
    "gold_metadata_df = npe_models['gold']['truth_df']\n",
    "silver_metadata_df = npe_models['silver']['truth_df']\n",
    "\n",
    "dbls_idxs = np.where(gold_metadata_df.loc[:,'point_source_parameters_num_images'].to_numpy() == 2.)[0]\n",
    "quads_idxs = np.where(gold_metadata_df.loc[:,'point_source_parameters_num_images'].to_numpy() == 4.)[0]\n",
    "\n",
    "# NOTE: hardcodings in this function for doubles and quads idxs\n",
    "NUM_FPD_SAMPS = int(500) \n",
    "def fpd_samps_helper(metadata_df,npe_mu,npe_cov,num_images):\n",
    "\n",
    "    if num_images == 2:\n",
    "        return mdv.fpd_gamma_samples(\n",
    "            x_im=metadata_df.loc[dbls_idxs,\n",
    "                ['point_source_parameters_x_image_0',\n",
    "                'point_source_parameters_x_image_1']].to_numpy(),\n",
    "            y_im=metadata_df.loc[dbls_idxs,\n",
    "                ['point_source_parameters_y_image_0',\n",
    "                'point_source_parameters_y_image_1']].to_numpy(),\n",
    "            npe_mu=npe_mu[dbls_idxs],npe_cov=npe_cov[dbls_idxs],\n",
    "            num_fpd_samps=NUM_FPD_SAMPS)\n",
    "    \n",
    "    elif num_images == 4:\n",
    "        return mdv.fpd_gamma_samples(\n",
    "            x_im=metadata_df.loc[quads_idxs,\n",
    "                ['point_source_parameters_x_image_0',\n",
    "                'point_source_parameters_x_image_1',\n",
    "                'point_source_parameters_x_image_2',\n",
    "                'point_source_parameters_x_image_3']].to_numpy(),\n",
    "            y_im=metadata_df.loc[quads_idxs,\n",
    "                ['point_source_parameters_y_image_0',\n",
    "                'point_source_parameters_y_image_1',\n",
    "                'point_source_parameters_y_image_2',\n",
    "                'point_source_parameters_y_image_3']].to_numpy(),\n",
    "            npe_mu=npe_mu[quads_idxs],npe_cov=npe_cov[quads_idxs],\n",
    "            num_fpd_samps=NUM_FPD_SAMPS)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Num images not supported\")\n",
    "\n",
    "# gold quads\n",
    "fpd_samps_gold_quads, lens_param_samps_gold_quads = fpd_samps_helper(\n",
    "    gold_metadata_df,npe_models['gold']['mu_npe'],\n",
    "    npe_models['gold']['cov_npe'],num_images=int(4))\n",
    "# gold doubles\n",
    "fpd_samps_gold_dbls, lens_param_samps_gold_dbls = fpd_samps_helper(\n",
    "    gold_metadata_df,npe_models['gold']['mu_npe'],npe_models['gold']['cov_npe'],num_images=2.)\n",
    "# silver quads\n",
    "fpd_samps_silver_quads, lens_param_samps_silver_quads = fpd_samps_helper(\n",
    "    silver_metadata_df,npe_models['silver']['mu_npe'],npe_models['silver']['cov_npe'],num_images=4.)\n",
    "# silver doubles\n",
    "fpd_samps_silver_dbls, lens_param_samps_silver_dbls = fpd_samps_helper(\n",
    "    silver_metadata_df,npe_models['silver']['mu_npe'],npe_models['silver']['cov_npe'],num_images=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39825946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write .h5 and store some beta_ani samps as well...\n",
    "\n",
    "def write_h5(h5_name,fpd_samps,lens_param_samps,catalog_idxs):\n",
    "\n",
    "    # FIRST: generate some beta_ani samps!\n",
    "    # truncate at beta_ani = -1...\n",
    "    beta_ani_samps = truncnorm.rvs(\n",
    "        (-1 - BETA_ANI_MU)/BETA_ANI_SIGMA, # lower truncation at -1\n",
    "        (1 - BETA_ANI_MU)/BETA_ANI_SIGMA, # upper truncation at 1\n",
    "        loc=BETA_ANI_MU,scale=BETA_ANI_SIGMA,\n",
    "        size=(fpd_samps_gold_quads.shape[0],fpd_samps_gold_quads.shape[1]))\n",
    "\n",
    "    # now, write the .h5 file and store all the samps...\n",
    "    h5f = h5py.File(h5_name, 'w')\n",
    "    h5f.create_dataset('catalog_idxs', data=catalog_idxs)\n",
    "    h5f.create_dataset('fpd_samps', data=fpd_samps)\n",
    "    h5f.create_dataset('lens_param_samps', data=lens_param_samps)\n",
    "    h5f.create_dataset('beta_ani_samps', data=beta_ani_samps)\n",
    "\n",
    "    # TODO: initialize empty kinematics??\n",
    "    h5f.create_dataset('c_sqrtJ_samps', data=-1*np.ones(\n",
    "        (fpd_samps_gold_quads.shape[0],fpd_samps_gold_quads.shape[1],1)))\n",
    "    h5f.close()\n",
    "\n",
    "# gold quads\n",
    "write_h5('DataVectors/gold/quad_posteriors.h5',\n",
    "    fpd_samps_gold_quads,lens_param_samps_gold_quads,\n",
    "    catalog_idxs=gold_metadata_df.loc[quads_idxs,'catalog_idx'].to_numpy())\n",
    "# gold doubles\n",
    "write_h5('DataVectors/gold/dbl_posteriors.h5',\n",
    "    fpd_samps_gold_dbls,lens_param_samps_gold_dbls,\n",
    "    catalog_idxs=gold_metadata_df.loc[dbls_idxs,'catalog_idx'].to_numpy())\n",
    "# silver quads\n",
    "write_h5('DataVectors/silver/quad_posteriors.h5',\n",
    "    fpd_samps_silver_quads,lens_param_samps_silver_quads,\n",
    "    catalog_idxs=silver_metadata_df.loc[quads_idxs,'catalog_idx'].to_numpy())\n",
    "# silver doubles\n",
    "write_h5('DataVectors/silver/dbl_posteriors.h5',\n",
    "    fpd_samps_silver_dbls,lens_param_samps_silver_dbls,\n",
    "    catalog_idxs=silver_metadata_df.loc[dbls_idxs,'catalog_idx'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6512a09",
   "metadata": {},
   "source": [
    "Now, we have to add in the kinematic model values that are consistent with the lens model samples. This is computationally expensive, so we develop code here, and then send to a cluster (takes ~30mins per lens for 500 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc958591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test how to write in kinematics into the .h5\n",
    "\n",
    "from filelock import FileLock\n",
    "import Modeling.Kinematics.galkin_utils as galkin_utils\n",
    "\n",
    "h5_posteriors_file = 'DataVectors/gold/quad_posteriors.h5'\n",
    "\n",
    "# read in fpd samps, lens_param_samps, beta_ani_samps\n",
    "with FileLock(h5_posteriors_file + \".lock\"):\n",
    "\n",
    "    h5 = h5py.File(h5_posteriors_file, 'r')\n",
    "    fpd_samps = h5['fpd_samps'][:]\n",
    "    lens_param_samps = h5['lens_param_samps'][:]\n",
    "    beta_ani_samps = h5['beta_ani_samps'][:]\n",
    "    catalog_idxs = h5['catalog_idxs'][:]\n",
    "    h5.close()\n",
    "\n",
    "# read in truth metadata\n",
    "truth_df = pd.read_csv('DataVectors/gold/truth_metadata.csv')\n",
    "\n",
    "# compute kinematics\n",
    "\n",
    "n_fpd_samps = np.shape(fpd_samps)[1]\n",
    "c_sqrtJ_samps = np.empty((n_fpd_samps,1))\n",
    "lens_idx = 0\n",
    "catalog_idx = catalog_idxs[lens_idx]\n",
    "R_sersic_truth = truth_df.loc[truth_df['catalog_idx']==catalog_idx,'lens_light_parameters_R_sersic'].item()\n",
    "n_sersic_truth = truth_df.loc[truth_df['catalog_idx']==catalog_idx,'lens_light_parameters_n_sersic'].item()\n",
    "\n",
    "# NOTE: only computing 10 samples (just to test things are working...)\n",
    "for fp_idx in range(0,10):\n",
    "\n",
    "    csqrtJ = galkin_utils.ground_truth_c_sqrtJ(\n",
    "        theta_E=lens_param_samps[lens_idx,fp_idx,0],\n",
    "        gamma_lens=lens_param_samps[lens_idx,fp_idx,3],\n",
    "        R_sersic=R_sersic_truth,n_sersic=n_sersic_truth,\n",
    "        beta_ani=beta_ani_samps[lens_idx,fp_idx])\n",
    "    c_sqrtJ_samps[fp_idx,0] = csqrtJ\n",
    "\n",
    "# filelock & write kinematics...\n",
    "with FileLock(h5_posteriors_file + \".lock\"):\n",
    "\n",
    "    h5 = h5py.File(h5_posteriors_file, 'r+')\n",
    "    h5['c_sqrtJ_samps'][lens_idx, ...] = c_sqrtJ_samps\n",
    "    h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bc23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify this works!\n",
    "h5 = h5py.File(h5_posteriors_file, 'r')\n",
    "print(h5['c_sqrtJ_samps'][0,:])\n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac357c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
